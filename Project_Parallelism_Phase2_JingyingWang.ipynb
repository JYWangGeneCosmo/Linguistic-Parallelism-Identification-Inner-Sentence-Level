{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import os\n",
    "import pandas as pd\n",
    "import csv\n",
    "import random\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/genecosmo/Desktop/Computer Applications in Linguistics \n",
      "\n",
      "['2009-01-20-Barack-Obama.txt', '2017-01-20-Donald-J-Trump.txt', '2001-01-20-George-W-Bush.txt']\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the 3 inaugural addresses in different times \n",
    "# (from the following years: 2001, 2009, 2017) for manual annotation work later.\n",
    "\n",
    "print(os.getcwd(), \"\\n\") # make use of the default path\n",
    "\n",
    "filelist = [fileid for fileid in os.listdir(\n",
    "    \"./American-Inaugural-Address-Corpus\") \n",
    "            if fileid[:4] in [ \"2001\", \"2009\", \"2017\"]]\n",
    "print(filelist) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "from nltk.tag.stanford import StanfordPOSTagger\n",
    "# enter the paths of Stanford POS Tagger .jar file as well as the model to be used\n",
    "jar = \"/Users/Shared/stanford-postagger-full-2018-10-16/stanford-postagger-3.9.2.jar\"\n",
    "model = \"/Users/Shared/stanford-postagger-full-2018-10-16/models/english-left3words-distsim.tagger\"\n",
    "# Instantiate an English pos-tagger using the jar and model defined above \n",
    "pos_tagger_en = StanfordPOSTagger(model, jar, encoding = \"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2009-01-20-Barack-Obama.txt\n",
      "2017-01-20-Donald-J-Trump.txt\n",
      "2001-01-20-George-W-Bush.txt\n"
     ]
    }
   ],
   "source": [
    "# Use Stanford POS-tagger defined above to Tag all source texts (English)\n",
    "\n",
    "for fileid in filelist:\n",
    "    if fileid.endswith(\".txt\"):                           # go through all English texts to apply tagger\n",
    "        print(fileid)            \n",
    "        with open (\"American-Inaugural-Address-Corpus/\" + fileid, encoding = \"utf-8\") as f:   \n",
    "            raw = f.read()\n",
    "            tokenized_text = word_tokenize(raw)              # tokenizing\n",
    "            tagged_text = pos_tagger_en.tag(tokenized_text)  # pos-tagging\n",
    "\n",
    "# Write the tagged text into new .txt files in specific format respectively\n",
    "\n",
    "        with open (\"American-Inaugural-Address-Corpus/tagged_\" + fileid, \"w\", encoding = \"utf-8\") as tag_f:\n",
    "            write_text = \"\"\n",
    "            for (a, b) in tagged_text:\n",
    "                write_text += a + \"_\" + b +\" \"   # combine word and tag together in the format: \"My_PRP$ \"\n",
    "            \n",
    "            # add newline character after the character which marks the end of a sentence \n",
    "            result = write_text.replace(\"_. \", \"_.\\n\").replace(\";_:\", \";_:\\n\").replace(\n",
    "            \":_:\", \":_:\\n\")   # \"_.\" include \"!\", \"?\" these sentence closers\n",
    "            \n",
    "                \n",
    "            tag_f.write(result)       # write all the results into corresponding .txt file     \n",
    "            \n",
    "\n",
    "for fileid in filelist:\n",
    "    with open (\"American-Inaugural-Address-Corpus/tagged_\"+ fileid) as f:\n",
    "        sentences = []\n",
    "        for row in f:\n",
    "            sentences.append(row)  \n",
    "        \n",
    "# Get corresponding .xlsx files which contain every sentence of the speech in the first column.\n",
    "        \n",
    "        df_sent = pd.DataFrame({\"sentence\" : sentences[:len(sentences)]})\n",
    "        df_sent.to_excel(\"American-Inaugural-Address-Corpus/Tagged_2/\"+ \n",
    "                    fileid + \"sent.xlsx\", encoding = \"utf-8\", index = False)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get indexes of all coordinators\n",
    "def get_index_of_coor(sent):\n",
    "    split_sent = sent.split()\n",
    "    indexes_of_coor = [-1]  # this ancillary element is used to compute the index of the first coordinator\n",
    "    for w in split_sent:\n",
    "        if w.startswith(\",\") or w.endswith(\"_CC\"):\n",
    "            # Use the formula to get the right index \n",
    "            # indexes_of_coor[-1] means the last element(index) of the index list\n",
    "            indexes_of_coor.append(split_sent.index(w) + indexes_of_coor[-1] +1 ) \n",
    "           \n",
    "            # chop the previous part of the sentence off (by +1) in order to find the next coordinator\n",
    "            split_sent = split_sent[(split_sent.index(w) +1) :]  \n",
    "            \n",
    "    # Exclude the conjunction at the beginning of the sentence, \n",
    "    # in order to avoid problem that could occur in \"similarity\" function        \n",
    "    if 0 in indexes_of_coor:   \n",
    "        indexes_of_coor = indexes_of_coor[2:]\n",
    "    else:\n",
    "        indexes_of_coor = indexes_of_coor[1:] # First ancillary index should be excluded\n",
    "    return indexes_of_coor  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_7 = \"But_CC know_VB this_DT ,_, America_NNP :_:\"\n",
    "get_index_of_coor(test_7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used for comparing 2 phrases as string\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "def compare(str1, str2):\n",
    "    return SequenceMatcher(None, str1, str2).ratio() \n",
    "# returns the similarity score (float in [0,1]) between input strings, the higher the score is, more similar 2 Strings are. \n",
    "\n",
    "\n",
    "def simi_structure(prev_str, after_str):\n",
    "    similar_phrase_pair = 0\n",
    "    if len(prev_str) > 6 and len(after_str) > 6:   # both sub-sentence contains more than two words\n",
    "            \n",
    "        if len(prev_str) == len(after_str):\n",
    "            if compare(prev_str[-len(after_str):], after_str) > 0.7:\n",
    "                similar_phrase_pair += 1\n",
    "        elif len(prev_str) - len(after_str) == 3:    # difference: 1 tag and prev_str is longer\n",
    "            if compare(prev_str[-len(after_str):], after_str) > 0.7 or compare(\n",
    "                prev_str[-len(after_str)-3 :], after_str) > 0.8:\n",
    "                similar_phrase_pair += 1\n",
    "        elif len(prev_str) - len(after_str) >= 6: # difference: at least 2 tags and prev_str is longer\n",
    "            if compare(prev_str[-len(after_str):], after_str) > 0.7 or compare(\n",
    "                prev_str[-len(after_str)-3 :], after_str) > 0.8 or compare(\n",
    "                prev_str[-len(after_str)-6 :], after_str) > 0.8:\n",
    "                similar_phrase_pair += 1\n",
    "        elif len(prev_str) - len(after_str) == -3:  # difference: 1 tag and after_str is longer\n",
    "            if compare(prev_str, after_str[: len(prev_str)]) > 0.7 or compare(\n",
    "                prev_str, after_str[: len(prev_str) + 3]) > 0.8:\n",
    "                similar_phrase_pair += 1\n",
    "        elif len(prev_str) - len(after_str) <= -6:   # difference: at least 2 tags and after_str is longer\n",
    "            if compare(prev_str, after_str[: len(prev_str)]) > 0.7 or compare(\n",
    "                prev_str, after_str[: len(prev_str) + 3]) > 0.8 or compare(\n",
    "                prev_str, after_str[: len(prev_str) + 6]) > 0.8:\n",
    "                similar_phrase_pair += 1\n",
    "    \n",
    "    elif len(prev_str) == 6 or len(after_str) == 6:    # at least one of the sub-sentence contains only two words\n",
    "\n",
    "        if len(prev_str) >= len(after_str):\n",
    "            if compare(prev_str[-len(after_str) :], after_str) == 1:     # both sequences within the same span should be identical to be considered as parallel\n",
    "                similar_phrase_pair += 1\n",
    "            \n",
    "        if len(prev_str) < len(after_str):\n",
    "            if compare(prev_str, after_str[: len(prev_str)]) == 1:\n",
    "                similar_phrase_pair += 1\n",
    "                \n",
    "        \n",
    "        \n",
    "    return similar_phrase_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t1:  1\n",
      "t2:  1\n",
      "t3:  1\n",
      "t4:  0\n",
      "t5:  0\n",
      "t6:  0\n",
      "t7:  1\n",
      "t8:  28\n",
      "t9:  1\n",
      "t10:  0\n",
      "t11:  0\n",
      "t12:  0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def similarity(sent):\n",
    "    similar_phrase_pair = 0\n",
    "    norm_sent = re.sub(\"...?_CC (also|not)_RB\", \",_,\", sent)  # nomalization: change \"but_CC also_RB/not_RB\" this kind of pattern into \",_,\"\n",
    "    norm_sent = re.sub(\",_,.?,_,\", \",_,\", norm_sent)     # last step could result with \",_, ,_,\"\n",
    "    norm_sent = re.sub(\",_, ...?_CC\", \",_,\", norm_sent)  # nomalization: change \",_, and_CC/or_CC/but_CC\" this kind of pattern into \",_,\"\n",
    "    coor_indexes = get_index_of_coor(norm_sent)\n",
    "    process_sent = norm_sent.split()[: -1]         # chop the \"sentence closer off\"\n",
    "           \n",
    "    if len(coor_indexes) == 1:   # only 2 sub-sentences\n",
    "        prev, after = process_sent[: coor_indexes[0]], process_sent[coor_indexes[0] + 1 :]\n",
    "        prev_str = \"\".join([w[w.index(\"_\") : w.index(\"_\") + 3] for w in prev])\n",
    "        after_str = \"\".join([w[w.index(\"_\") : w.index(\"_\") + 3] for w in after])\n",
    "        similar_phrase_pair += simi_structure(prev_str, after_str)\n",
    "        \n",
    "    elif len(coor_indexes) > 1:\n",
    "        prev = process_sent[: coor_indexes[0]]\n",
    "        for ii in range(len(coor_indexes) - 1):\n",
    "            after = process_sent[coor_indexes[ii] + 1 : coor_indexes[ii + 1]]\n",
    "            prev_str = \"\".join([w[w.index(\"_\") : w.index(\"_\") + 3] for w in prev])\n",
    "            after_str = \"\".join([w[w.index(\"_\") : w.index(\"_\") + 3] for w in after])\n",
    "            #print(\"pre\", prev_str, \"af\", after_str)\n",
    "            similar_phrase_pair += simi_structure(prev_str, after_str)\n",
    "            prev = after\n",
    "        after = process_sent[coor_indexes[-1] + 1 :]\n",
    "        prev_str = \"\".join([w[w.index(\"_\") : w.index(\"_\") + 3] for w in prev])\n",
    "        after_str = \"\".join([w[w.index(\"_\") : w.index(\"_\") + 3] for w in after])\n",
    "        #print(\"pre\", prev_str, \"af\", after_str)\n",
    "        similar_phrase_pair += simi_structure(prev_str, after_str)\n",
    "        \n",
    "    if similar_phrase_pair == 0:\n",
    "        if len(process_sent) > 4:   # at least 4 words\n",
    "            tag_sequence = [w[w.index(\"_\") : w.index(\"_\") + 3] for w in process_sent]\n",
    "            #print(tag_sequence)\n",
    "            tag_bigram_list = [bi for bi in nltk.bigrams(tag_sequence)]\n",
    "            for index_w in range(len(tag_sequence) - 4):\n",
    "                if tag_sequence[index_w] == tag_sequence[index_w + 2] == tag_sequence[index_w + 4]:\n",
    "                    for index in range(len(tag_bigram_list) - 2):\n",
    "                        if tag_bigram_list[index] == tag_bigram_list[index + 2] and (tag_bigram_list[index][0] == \"_CC\" or tag_bigram_list[index][0] == \"_,\"):\n",
    "                            similar_phrase_pair += 1\n",
    "            \n",
    "    \n",
    "    return similar_phrase_pair\n",
    "\n",
    "\n",
    "    \n",
    "test_sent1 = \"In_IN the_DT year_NN of_IN America_NNP 's_POS birth_NN ,_, in_IN the_DT coldest_JJS of_IN months_NNS ,_, a_DT small_JJ band_NN of_IN patriots_NNS huddled_VBN by_IN dying_VBG campfires_NNS on_IN the_DT shores_NNS of_IN an_DT icy_NN river_NN ._.\"\n",
    "test_sent2 = \"And_CC each_DT day_NN brings_VBZ further_JJ evidence_NN that_IN the_DT ways_NNS we_PRP use_VBP energy_NN strengthen_VB our_PRP$ adversaries_NNS and_CC threaten_VB our_PRP$ planet_NN ._.\"\n",
    "test_sent3 = \"America_NNP has_VBZ never_RB been_VBN united_VBN by_IN blood_NN or_CC birth_NN or_CC soil_NN ._.\"  \n",
    "t4 = \"I_PRP thank_VBP President_NNP Bush_NNP for_IN his_PRP$ service_NN to_TO our_PRP$ Nation_NNP ,_, as_RB well_RB as_IN the_DT generosity_NN and_CC cooperation_NN he_PRP has_VBZ shown_VBN throughout_IN this_DT transition_NN ._.\"\n",
    "t5 = \" an_DT education_NN system_NN ,_, flush_NN with_IN cash_NN ,_, but_CC which_WDT leaves_VBZ our_PRP$ young_JJ and_CC beautiful_JJ students_NNS deprived_VBN of_IN all_DT knowledge_NN ;_:\"\n",
    "t6 = \"Our_PRP$ Nation_NN is_VBZ at_IN war_NN against_IN a_DT far-reaching_JJ network_NN of_IN violence_NN and_CC hatred_NN ._.\"\n",
    "t7 = \"The_DT peaceful_JJ transfer_NN of_IN authority_NN is_VBZ rare_JJ in_IN history_NN ,_, yet_RB common_JJ in_IN our_PRP$ country_NN ._.\"\n",
    "t8 = \"We_PRP will_MD build_VB new_JJ roads_NNS and_CC highways_NNS and_CC bridges_NNS and_CC airports_NNS and_CC tunnels_NNS and_CC railways_NNS all_DT across_IN our_PRP$ wonderful_JJ Nation_NN ._.\"\n",
    "t9 = \"So_RB when_WRB I_PRP was_VBD a_DT little_JJ girl_NN ,_, a_DT book_NN sat_VBD on_IN the_DT coffee_NN table_NN in_IN our_PRP$ living_NN room_NN ,_, just_RB steps_NNS from_IN our_PRP$ front_JJ door_NN ._.\"\n",
    "t10 = \"And_CC we_PRP will_MD reduce_VB taxes_NNS to_TO recover_VB the_DT momentum_NN of_IN our_PRP$ economy_NN and_CC reward_VB the_DT effort_NN and_CC enterprise_NN of_IN working_VBG Americans_NNPS ._.\"\n",
    "t11 = \"It_PRP is_VBZ the_DT firefighter_NN 's_POS courage_NN to_TO storm_VB a_DT stairway_NN filled_VBN with_IN smoke_NN ,_, but_CC also_RB a_DT parent_NN 's_POS willingness_NN to_TO nurture_VB a_DT child_NN ,_, that_WDT finally_RB decides_VBZ our_PRP$ fate_NN ._.\"\n",
    "t12 = \" a_DT book_NN sat_VBD on_IN the_DT coffee_NN table_NN in_IN our_PRP$ living_NN room_NN ,_, just_RB steps_NNS from_IN our_PRP$ front_JJ door_NN\"\n",
    "print(\"t1: \", similarity(test_sent1))\n",
    "print(\"t2: \", similarity(test_sent2))\n",
    "print(\"t3: \", similarity(test_sent3))\n",
    "print(\"t4: \", similarity(t4))\n",
    "print(\"t5: \", similarity(t5))\n",
    "print(\"t6: \", similarity(t6))\n",
    "print(\"t7: \", similarity(t7))\n",
    "print(\"t8: \", similarity(t8))\n",
    "print(\"t9: \", similarity(t9))\n",
    "print(\"t10: \", similarity(t10))\n",
    "print(\"t11: \", similarity(t11))\n",
    "print(\"t12: \", similarity(t12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity(\"Online_NN by_IN Gerhard_NNP Peters_NNP and_CC John_NNP T._NNP Woolley_NNP ,_, The_NNP American_NNP Presidency_NNP Project_NNP ._.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(sent):\n",
    "    feature = {}\n",
    "    feature[\"simi\"] = similarity(sent) > 0\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define this function for evaluation\n",
    "def compute_PRF(gold, predicted, class_label):\n",
    "    TP = sum(int(g == class_label and p == class_label) for (g, p) in zip (gold, predicted))\n",
    "    FP = sum(int(p == class_label and g != class_label) for (g, p) in zip (gold, predicted)) \n",
    "    FN = sum(int(p != class_label and g == class_label) for (g, p) in zip (gold, predicted))\n",
    "    if TP + FP > 0:\n",
    "        precision = TP/(TP + FP)\n",
    "    else:\n",
    "        precision = 0\n",
    "    if TP + FN > 0:\n",
    "        recall = TP/(TP + FN)\n",
    "    else:\n",
    "        recall = 0\n",
    "    if precision > 0 and recall > 0:\n",
    "        f_measure = 2 * precision * recall / (precision + recall)\n",
    "    else:\n",
    "        f_measure = 0\n",
    "    \n",
    "    return 'Precision=%.2f Recall=%.2f F_Measure=%.2f'  %  (precision, recall, f_measure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "380\n",
      "[('Inaugural_JJ Address_NNP January_NNP 20_CD ,_, 2009_CD Public_NNP Papers_NNP of_IN the_DT Presidents_NNS Barack_NNP Obama_NNP <_JJR br_NN >_JJR 2009_CD :_:\\n', 'f'), (' Book_VB I_PRP Barack_NNP Obama_NNP 2009_CD :_:\\n', 'f'), (' Book_VB I_PRP Location_NNP :_:\\n', 'f'), (' District_NNP of_IN Columbia_NNP Washington_NNP The_NNP American_NNP Presidency_NNP Project_NNP\\n', 'f'), ('My_PRP$ fellow_JJ citizens_NNS ,_, I_PRP stand_VBP here_RB today_NN humbled_VBN by_IN the_DT task_NN before_IN us_PRP ,_, grateful_JJ for_IN the_DT trust_NN you_PRP have_VBP bestowed_VBN ,_, mindful_JJ of_IN the_DT sacrifices_NNS borne_VBN by_IN our_PRP$ ancestors_NNS ._.', 't')]\n"
     ]
    }
   ],
   "source": [
    "data_set_raw1 = []\n",
    "for file in os.listdir(\"American-Inaugural-Address-Corpus/Tagged\"):\n",
    "    if file.endswith(\"csv\"):\n",
    "        with open(\"American-Inaugural-Address-Corpus/Tagged/\" + file, encoding = \"utf-8\") as f:\n",
    "            reader = csv.reader(f, delimiter = \",\")\n",
    "            rows = [row for row in reader]\n",
    "            data_set_raw1.extend(rows[1:])   # the first row is the header [\"sentence\", \"Tag\"], so not needed\n",
    "print(len(data_set_raw1))\n",
    "data_set = [(sent, tag) for [sent, tag] in data_set_raw1]\n",
    "print(data_set[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152\n"
     ]
    }
   ],
   "source": [
    "random.Random(2).shuffle(data_set) \n",
    "featuresets = [(get_features(sent), tag) for (sent, tag) in data_set ]\n",
    "size = len(featuresets)\n",
    "train_set, devtest_set = featuresets[:size*6//10], featuresets[size*6//10:]\n",
    "print(len(devtest_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier1 = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9276315789473685"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.classify.accuracy(classifier1, devtest_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                    simi = True                t : f      =     10.8 : 1.0\n",
      "                    simi = False               f : t      =      4.9 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier1.show_most_informative_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Precision=0.84 Recall=0.93 F_Measure=0.89'"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold = [tag for (sent_feature, tag) in devtest_set]\n",
    "pred = [classifier1.classify(sent_feature) for (sent_feature, tag) in devtest_set]\n",
    "compute_PRF(gold, pred, \"t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'f'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier1.classify(get_features(\"We_PRP treat_VBP it_PRP like_IN a_DT nice-to-have_JJ instead_RB of_IN a_DT must-have_JJ ._.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Inaugural_JJ Address_NNP January_NNP 20_CD ,_, 2009_CD Public_NNP Papers_NNP of_IN the_DT Presidents_NNS Barack_NNP Obama_NNP <_JJR br_NN >_JJR 2009_CD :_:\\n', 'f'], [' Book_VB I_PRP Barack_NNP Obama_NNP 2009_CD :_:\\n', 'f'], [' Book_VB I_PRP Location_NNP :_:\\n', 'f']]\n"
     ]
    }
   ],
   "source": [
    "data_set_raw = []\n",
    "for file in os.listdir(\"American-Inaugural-Address-Corpus/Tagged\"):\n",
    "    if file.endswith(\"csv\"):\n",
    "        with open(\"American-Inaugural-Address-Corpus/Tagged/\" + file, encoding = \"utf-8\") as f:\n",
    "            reader = csv.reader(f, delimiter = \",\")\n",
    "            rows = [row for row in reader]\n",
    "            data_set_raw.extend(rows[1:])\n",
    "print(data_set_raw[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "380"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_data = []\n",
    "for [sent, tag] in data_set_raw:\n",
    "    features_tag = []\n",
    "    simi = similarity(sent) \n",
    "    features_tag.extend([sent,simi,tag])\n",
    "    transformed_data.append(features_tag)  # use append to maintain list form\n",
    "len(transformed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent</th>\n",
       "      <th>simi</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Inaugural_JJ Address_NNP January_NNP 20_CD ,_,...</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Book_VB I_PRP Barack_NNP Obama_NNP 2009_CD :_:\\n</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Book_VB I_PRP Location_NNP :_:\\n</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>District_NNP of_IN Columbia_NNP Washington_NN...</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>My_PRP$ fellow_JJ citizens_NNS ,_, I_PRP stand...</td>\n",
       "      <td>1</td>\n",
       "      <td>t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I_PRP thank_VBP President_NNP Bush_NNP for_IN ...</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Forty-four_CD Americans_NNPS have_VBP now_RB t...</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The_DT words_NNS have_VBP been_VBN spoken_VBN ...</td>\n",
       "      <td>1</td>\n",
       "      <td>t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Yet_CC every_DT so_RB often_RB ,_, the_DT oath...</td>\n",
       "      <td>1</td>\n",
       "      <td>t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>At_IN these_DT moments_NNS ,_, America_NNP has...</td>\n",
       "      <td>0</td>\n",
       "      <td>t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>So_IN it_PRP has_VBZ been_VBN ;_:\\n</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>so_IN it_PRP must_MD be_VB with_IN this_DT ge...</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>That_DT we_PRP are_VBP in_IN the_DT midst_NN o...</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Our_PRP$ Nation_NN is_VBZ at_IN war_NN against...</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Our_PRP$ economy_NN is_VBZ badly_RB weakened_V...</td>\n",
       "      <td>1</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Homes_NNPS have_VBP been_VBN lost_VBN ,_, jobs...</td>\n",
       "      <td>1</td>\n",
       "      <td>t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Our_PRP$ health_NN care_NN is_VBZ too_RB costl...</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Our_PRP$ schools_NNS fail_VBP too_RB many_JJ ....</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>And_CC each_DT day_NN brings_VBZ further_JJ ev...</td>\n",
       "      <td>1</td>\n",
       "      <td>t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>These_DT are_VBP the_DT indicators_NNS of_IN c...</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 sent  simi tag\n",
       "0   Inaugural_JJ Address_NNP January_NNP 20_CD ,_,...     0   f\n",
       "1    Book_VB I_PRP Barack_NNP Obama_NNP 2009_CD :_:\\n     0   f\n",
       "2                    Book_VB I_PRP Location_NNP :_:\\n     0   f\n",
       "3    District_NNP of_IN Columbia_NNP Washington_NN...     0   f\n",
       "4   My_PRP$ fellow_JJ citizens_NNS ,_, I_PRP stand...     1   t\n",
       "5   I_PRP thank_VBP President_NNP Bush_NNP for_IN ...     0   f\n",
       "6   Forty-four_CD Americans_NNPS have_VBP now_RB t...     0   f\n",
       "7   The_DT words_NNS have_VBP been_VBN spoken_VBN ...     1   t\n",
       "8   Yet_CC every_DT so_RB often_RB ,_, the_DT oath...     1   t\n",
       "9   At_IN these_DT moments_NNS ,_, America_NNP has...     0   t\n",
       "10                So_IN it_PRP has_VBZ been_VBN ;_:\\n     0   f\n",
       "11   so_IN it_PRP must_MD be_VB with_IN this_DT ge...     0   f\n",
       "12  That_DT we_PRP are_VBP in_IN the_DT midst_NN o...     0   f\n",
       "13  Our_PRP$ Nation_NN is_VBZ at_IN war_NN against...     0   f\n",
       "14  Our_PRP$ economy_NN is_VBZ badly_RB weakened_V...     1   f\n",
       "15  Homes_NNPS have_VBP been_VBN lost_VBN ,_, jobs...     1   t\n",
       "16  Our_PRP$ health_NN care_NN is_VBZ too_RB costl...     0   f\n",
       "17  Our_PRP$ schools_NNS fail_VBP too_RB many_JJ ....     0   f\n",
       "18  And_CC each_DT day_NN brings_VBZ further_JJ ev...     1   t\n",
       "19  These_DT are_VBP the_DT indicators_NNS of_IN c...     0   f"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data = pd.DataFrame(transformed_data, columns = ['sent','simi','tag'])\n",
    "df_data.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data[\"tag_num\"] = df_data.tag.map({'f' : 0, 't' : 1})\n",
    "df_data.to_excel(\"American-Inaugural-Address-Corpus/Tagged/transformed.xlsx\", \n",
    "                 encoding = \"utf-8\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = ['simi']\n",
    "# select all 10 features (X)\n",
    "X = df_data[feature_cols]\n",
    "# select numerical tag as response (y)\n",
    "y = df_data.tag_num "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use cross validation to evaluate the results:\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(285, 1)\n",
      "(95, 1)\n",
      "(285,)\n",
      "(95,)\n"
     ]
    }
   ],
   "source": [
    "sent_train, sent_dev, tag_train, tag_dev = train_test_split(X, y, test_size = 0.25, random_state = 1)\n",
    "print(sent_train.shape)\n",
    "print(sent_dev.shape)\n",
    "print(tag_train.shape)\n",
    "print(tag_dev.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try different algorithms\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize classifiers\n",
    "knn = KNeighborsClassifier(n_neighbors = 1)\n",
    "lr = LogisticRegression()\n",
    "svc = LinearSVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tryClassifier(clf):\n",
    "    print(type(clf))\n",
    "    clf.fit(sent_train, tag_train)\n",
    "    tag_pred = clf.predict(sent_dev)\n",
    "    print('Acc: ', metrics.accuracy_score(tag_dev, tag_pred))\n",
    "    print(compute_PRF(tag_dev, tag_pred, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.neighbors.classification.KNeighborsClassifier'>\n",
      "Acc:  0.9263157894736842\n",
      "Precision=0.82 Recall=0.92 F_Measure=0.87\n",
      "<class 'sklearn.linear_model.logistic.LogisticRegression'>\n",
      "Acc:  0.9263157894736842\n",
      "Precision=0.82 Recall=0.92 F_Measure=0.87\n",
      "<class 'sklearn.svm.classes.LinearSVC'>\n",
      "Acc:  0.9263157894736842\n",
      "Precision=0.82 Recall=0.92 F_Measure=0.87\n"
     ]
    }
   ],
   "source": [
    "tryClassifier(knn)\n",
    "tryClassifier(lr)\n",
    "tryClassifier(svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file_sent(path):   # path of the file as string\n",
    "    with open (path, encoding = \"utf-8\") as f:   \n",
    "        raw = f.read()\n",
    "        tokenized_text = word_tokenize(raw)              # tokenizing\n",
    "        tagged_text = pos_tagger_en.tag(tokenized_text)  # pos-tagging\n",
    "        \n",
    "    with open (path + \"processed\", \"w\", encoding = \"utf-8\") as processed_f:\n",
    "        write_text = \"\"\n",
    "        for (a, b) in tagged_text:\n",
    "            write_text += a + \"_\" + b +\" \"   # combine word and tag together in the format: \"My_PRP$ \"\n",
    "            \n",
    "            # add newline character after the character which marks the end of a sentence \n",
    "        result = write_text.replace(\"_. \", \"_.\\n\").replace(\";_:\", \";_:\\n\").replace(\n",
    "            \":_:\", \":_:\\n\")   # \"_.\" include \"!\", \"?\" these sentence closers\n",
    "                \n",
    "        processed_f.write(result)       # write all the results into corresponding .txt file         \n",
    "            \n",
    "    with open (path + \"processed\") as f:\n",
    "        sentences = []\n",
    "        for row in f:\n",
    "            sentences.append(row)  \n",
    "\n",
    "# Get corresponding .xlsx files which contain every sentence of the speech in the first column.\n",
    "        \n",
    "        df_sent = pd.DataFrame({\"sentence\" : sentences[:len(sentences)]})\n",
    "        df_sent.to_csv (path + \"processed_sent.csv\", encoding = \"utf-8\", index = False)\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform (path): # path of the file as string\n",
    "    with open (path + \"processed_sent.csv\") as f:\n",
    "        reader = csv.reader(f, delimiter = \",\")\n",
    "        rows = [row for row in reader]\n",
    "        transformed_data = []\n",
    "        for [sent] in rows[1:]:   # \"sentence\" in the first row?\n",
    "            features = []\n",
    "            simi = similarity(sent) > 0\n",
    "            features.extend([sent, simi])\n",
    "            transformed_data.append(features)  # use append to maintain list form\n",
    "        \n",
    "        df_data = pd.DataFrame(transformed_data, columns = ['sent','simi'])\n",
    "        \n",
    "    return df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_file_sklearn (path, clf): # path of the file as string\n",
    "    df_data = transform(path)\n",
    "    X_features_test = df_data[feature_cols]\n",
    "    y_tag_pred = clf.predict(X_features_test)\n",
    "    df_data[\"tag\"] = y_tag_pred\n",
    "    df_data[\"tag\"] = df_data.tag.map({ 0 : 'FALSE' , 1 : 'TRUE'})\n",
    "    df_data.to_csv(path + \"tagged.csv\", encoding = \"utf-8\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_file_nltk (path, clf): # path of the file as string\n",
    "    with open (path, encoding = \"utf-8\") as f:   \n",
    "        raw = f.read()\n",
    "        tokenized_text = word_tokenize(raw)              # tokenizing\n",
    "        tagged_text = pos_tagger_en.tag(tokenized_text)  # pos-tagging\n",
    "        \n",
    "    with open (path + \"processed\", \"w\", encoding = \"utf-8\") as processed_f:\n",
    "        write_text = \"\"\n",
    "        for (a, b) in tagged_text:\n",
    "            write_text += a + \"_\" + b +\" \"   # combine word and tag together in the format: \"My_PRP$ \"\n",
    "            \n",
    "            # add newline character after the character which marks the end of a sentence \n",
    "        result = write_text.replace(\"_. \", \"_.\\n\").replace(\";_:\", \";_:\\n\").replace(\n",
    "            \":_:\", \":_:\\n\")   # \"_.\" include \"!\", \"?\" these sentence closers\n",
    "                \n",
    "        processed_f.write(result)       # write all the results into corresponding .txt file         \n",
    "            \n",
    "    with open (path + \"processed\") as f:\n",
    "        sentences = []\n",
    "        for row in f:\n",
    "            sentences.append(row)\n",
    "        df_data = pd.DataFrame({\"sentence\" : sentences[:len(sentences)]})    \n",
    "        tag_pred = [clf.classify(get_features(sent)) for sent in sentences] \n",
    "        df_data[\"tag\"] = tag_pred\n",
    "        df_data[\"tag\"] = df_data.tag.map({ \"f\" : 'FALSE' , 't' : 'TRUE'})\n",
    "        df_data.to_csv(path + \"tagged.csv\", encoding = \"utf-8\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_file_sent(\"/Users/genecosmo/Desktop/Computer Applications in Linguistics/test_classifier/phase2_svc/testted.txt\")\n",
    "transform(\"/Users/genecosmo/Desktop/Computer Applications in Linguistics/test_classifier/phase2_svc/testted.txt\")\n",
    "tag_file_sklearn(\"/Users/genecosmo/Desktop/Computer Applications in Linguistics/test_classifier/phase2_svc/testted.txt\", svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_file_sent(\"/Users/genecosmo/Desktop/Computer Applications in Linguistics/test_classifier/phase2_nb/testted.txt\")\n",
    "transform(\"/Users/genecosmo/Desktop/Computer Applications in Linguistics/test_classifier/phase2_nb/testted.txt\")\n",
    "tag_file_nltk(\"/Users/genecosmo/Desktop/Computer Applications in Linguistics/test_classifier/phase2_nb/testted.txt\", classifier1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
